{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading customers.csv\n",
    "df_customers = pd.read_csv('C:\\Desktop\\Python Projects\\Supply Chain Analysis\\output_data_large\\customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows based on customerID\n",
    "df_customers = df_customers.drop_duplicates(subset=['CustomerID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Clean Phone numbers\n",
    "import re\n",
    "def clean_phone_number(phone):\n",
    "    # Remove all non-numeric characters except \"+\"\n",
    "    phone = re.sub(r'[^0-9+]', '', phone)\n",
    "    \n",
    "    # If it starts with a 0, replace it with the Australian country code (+61)\n",
    "    if phone.startswith('0'):\n",
    "        phone = '+61' + phone[1:]\n",
    "    \n",
    "    # If it doesn't start with \"+\", assume it's missing the country code and add +61\n",
    "    elif not phone.startswith('+'):\n",
    "        phone = '+61' + phone\n",
    "    \n",
    "    # Return cleaned phone number\n",
    "    return phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers['CustomerPhoneNumber'] =df_customers['CustomerPhoneNumber'].apply(clean_phone_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Drop rows where CustomerEmail is missing\n",
    "df_customers = df_customers.dropna(subset=['CustomerEmail'])\n",
    "# Step 3: Fix invalid postal codes (replace 'XXX' with '0000')\n",
    "df_customers['PostalCode'] = df_customers['PostalCode'].replace({'XXX': '0000'})\n",
    "# Step 4: Convert Customer ID to Integer\n",
    "df_customers['CustomerID'] = df_customers['CustomerID'].astype(int)\n",
    "df_customers.to_csv('cleaned_customers.csv', index=False)\n",
    "print(\"Cleaned customers.csv saved as cleaned_customers.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading employees.csv\n",
    "df_employees = pd.read_csv('C:\\Desktop\\Python Projects\\Supply Chain Analysis\\output_data_large\\employees.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove duplicate rows based on EmployeeID\n",
    "df_employees = df_employees.drop_duplicates(subset=['EmployeeID'])\n",
    "# Step 2: Remove rows where EmployeeEmail is missing\n",
    "df_employees = df_employees.dropna(subset=['EmployeeEmail'])\n",
    "# Step 3: Convert EmployeeID to integer\n",
    "df_employees['EmployeeID'] = df_employees['EmployeeID'].astype(int)\n",
    "# Save the cleaned file\n",
    "df_employees.to_csv('cleaned_employees.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading products.csv\n",
    "df_products = pd.read_csv('C:\\Desktop\\Python Projects\\Supply Chain Analysis\\output_data_large\\products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove duplicate rows based on ProductID\n",
    "df_products = df_products.drop_duplicates(subset=['ProductID'])\n",
    "# Step 2: Remove rows with negative UnitPrice\n",
    "df_products = df_products[df_products['UnitPrice'] >= 0]\n",
    "# Step 3: Fill missing values in UnitPrice with the median value\n",
    "median_price = df_products['UnitPrice'].median()\n",
    "df_products['UnitPrice'] = df_products['UnitPrice'].fillna(median_price)\n",
    "# Step 4: Convert ProductID to integer\n",
    "df_products['ProductID'] = df_products['ProductID'].astype(int)\n",
    "# Save the cleaned file\n",
    "df_products.to_csv('cleaned_products.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading warehouses.csv\n",
    "df_warehouses = pd.read_csv('C:\\Desktop\\Python Projects\\Supply Chain Analysis\\output_data_large\\warehouses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove duplicate rows based on WarehouseID\n",
    "df_warehouses = df_warehouses.drop_duplicates(subset=['WarehouseID'])\n",
    "# Step 2: Fix invalid postal codes (replace 'XXX' with '0000')\n",
    "df_warehouses['PostalCode'] = df_warehouses['PostalCode'].replace({'XXX': '0000'})\n",
    "# Step 3: Convert WarehouseID to integer\n",
    "df_warehouses['WarehouseID'] = df_warehouses['WarehouseID'].astype(int)\n",
    "\n",
    "# Save the cleaned file\n",
    "df_warehouses.to_csv('cleaned_warehouses.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading orders.csv\n",
    "df_orders = pd.read_csv('C:\\Desktop\\Python Projects\\Supply Chain Analysis\\output_data_large\\orders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove duplicate rows based on OrderID\n",
    "df_orders = df_orders.drop_duplicates(subset=['OrderID'])\n",
    "# Step 2: Drop rows with missing OrderID or CustomerID\n",
    "df_orders = df_orders.dropna(subset=['OrderID', 'CustomerID'])\n",
    "# Step 3: Remove rows with negative FuelCharge\n",
    "df_orders = df_orders[df_orders['FuelCharge'] >= 0]\n",
    "# Step 4: Convert dates to datetime\n",
    "df_orders['OrderDate'] = pd.to_datetime(df_orders['OrderDate'])\n",
    "df_orders['ShippedDate'] = pd.to_datetime(df_orders['ShippedDate'], errors='coerce')  # Allow NaT for missing dates\n",
    "df_orders['DeliveryDate'] = pd.to_datetime(df_orders['DeliveryDate'], errors='coerce')  # Allow NaT for missing dates\n",
    "# Step 5: Remove invalid date ranges (e.g., ShippedDate before OrderDate, DeliveryDate before ShippedDate)\n",
    "df_orders = df_orders[df_orders['ShippedDate'] >= df_orders['OrderDate']]\n",
    "df_orders = df_orders[df_orders['DeliveryDate'] >= df_orders['ShippedDate']]\n",
    "# Save the cleaned file\n",
    "df_orders.to_csv('cleaned_orders.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading order_details.csv\n",
    "df_order_details = pd.read_csv('C:\\Desktop\\Python Projects\\Supply Chain Analysis\\output_data_large\\order_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove duplicate rows based on OrderDetailID\n",
    "df_order_details = df_order_details.drop_duplicates(subset=['OrderDetailID'])\n",
    "# Step 2: Remove rows with negative quantities\n",
    "df_order_details = df_order_details[df_order_details['Quantity'] > 0]\n",
    "# Step 3: Convert OrderID and ProductID to integer\n",
    "df_order_details['OrderID'] = df_order_details['OrderID'].astype(int)\n",
    "df_order_details['ProductID'] = df_order_details['ProductID'].astype(int)\n",
    "# Save the cleaned file\n",
    "df_order_details.to_csv('cleaned_order_details.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
